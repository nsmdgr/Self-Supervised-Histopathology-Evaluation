{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76745571-ae6f-4952-880c-cbe3ce857fbc",
   "metadata": {},
   "source": [
    "# Classification Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8751f2f-5958-48da-ad32-1ac425dc6219",
   "metadata": {},
   "source": [
    "## BACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d28c03-c4c0-437f-bcc2-1fa5b7bc33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder, MNIST\n",
    "from pathlib import Path\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url, download_and_extract_archive\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "143d0540-282e-459e-8482-2eb31fde18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('/home/niklas/Internal_HDD/project_data/histopathology/BACH/ICIAR2018_BACH_Challenge/Photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1205160a-9a22-4c6f-8ad2-bbc9a2899030",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = torch.tensor([0.7169, 0.6170, 0.8427]), torch.tensor([0.1661, 0.1885, 0.1182]) # calculated over dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd19c665-6f92-4200-8b46-731e9716a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bach:\n",
    "    \n",
    "    def __init__(self, root, train_transform, valid_transform, download=False, valid_percent=0.2, shuffle=True):\n",
    "        \n",
    "        self.root = root\n",
    "        self.train_transform = train_transform\n",
    "        self.valid_transform = valid_transform\n",
    "        self.valid_percent = valid_percent\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if download:\n",
    "            self.download_data()\n",
    "            self.root = self.root/'ICIAR2018_BACH_Challenge/Photos' # extend root directory to point to images\n",
    "            \n",
    "        self.train_ds, self.valid_ds, self.train_sampler, self.valid_sampler = self.prepare_datasets()\n",
    "        \n",
    "    def download_data(self):\n",
    "        url = 'https://zenodo.org/record/3632035/files/ICIAR2018_BACH_Challenge.zip'\n",
    "        download_and_extract_archive(url, self.root)\n",
    "    \n",
    "    def prepare_datasets(self):\n",
    "        train_ds = ImageFolder(self.root, self.train_transform)\n",
    "        valid_ds = ImageFolder(self.root, self.valid_transform)\n",
    "        \n",
    "        num_train = len(train_ds)\n",
    "        indices   = list(range(num_train))\n",
    "        split     = int(np.floor(self.valid_percent * num_train))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            rng = default_rng(seed=101)\n",
    "            rng.shuffle(indices)\n",
    "        \n",
    "        train_idx, valid_idx = indices[split:], indices[:split]\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "        \n",
    "        return train_ds, valid_ds, train_sampler, valid_sampler\n",
    "    \n",
    "    def get_dataloaders(self, batch_size, shuffle=True, pin_memory=True, num_workers=0):\n",
    "        train_dl = DataLoader(\n",
    "            self.train_ds, batch_size=batch_size, sampler=self.train_sampler,\n",
    "            num_workers=num_workers, pin_memory=pin_memory\n",
    "        )\n",
    "        \n",
    "        valid_dl = DataLoader(\n",
    "            self.valid_ds, batch_size=batch_size, sampler=self.valid_sampler,\n",
    "            num_workers=num_workers, pin_memory=pin_memory\n",
    "        )\n",
    "        \n",
    "        return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c77422a-8912-4e77-868e-f9c407934b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f2f950c-4bb2-4943-8e86-817fb5f87d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bach = Bach(p, train_transform, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b214fc0-a991-4599-91a9-8171129f8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = bach.get_dataloaders(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "025f3e51-85b6-466c-b6cd-5c98be9d7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "42b0d064-03b6-4909-8fe0-ff24a0017ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(loader):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for i, (data, _) in enumerate(loader):\n",
    "        print(f'{i+1}/{len(loader)}', ' '*100, end='\\r')\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "#mean, std = get_mean_std(dl)\n",
    "#print(mean)\n",
    "#print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bece5-7b9a-4a51-a1cb-ab18ba398061",
   "metadata": {},
   "source": [
    "## Patchcamelyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe484867-e822-43ed-8525-89c9df25511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchCamelyonDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, transform, mode='train'):\n",
    "        super().__init__()\n",
    "\n",
    "        assert mode in ['train', 'valid', 'test']\n",
    "        \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        self.X = h5py.File(root/f'camelyonpatch_level_2_split_{mode}_x.h5', 'r').get('x')\n",
    "        self.y = h5py.File(root/f'camelyonpatch_level_2_split_{mode}_y.h5', 'r').get('y')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.X[idx], self.y[idx]\n",
    "        x, y = self.transform(x), y.item()\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b36ef15-7a77-4be5-92b5-00bac891bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchCamelyon:\n",
    "    \n",
    "    def __init__(self, root, train_transform, valid_transform, download=False):\n",
    "        \n",
    "        self.root = root\n",
    "        self.train_transform = train_transform\n",
    "        self.valid_transform = valid_transform\n",
    "        \n",
    "        if download:\n",
    "            self.download_data()\n",
    "            \n",
    "        self.train_ds, self.valid_ds, self.test_ds = self.prepare_datasets()\n",
    "        \n",
    "    def download_data(self):\n",
    "        base_url = 'https://zenodo.org/record/2546921/files/'\n",
    "        for mode in ['train', 'valid', 'test']:\n",
    "            download_url(base_url + f'camelyonpatch_level_2_split_{mode}_meta.csv', self.root)\n",
    "            for xy in ['x','y']: \n",
    "                download_and_extract_archive(base_url + f'camelyonpatch_level_2_split_{mode}_{xy}.h5.gz', self.root)\n",
    "    \n",
    "    def prepare_datasets(self):\n",
    "        train_ds = PatchCamelyonDataset(self.root, transform=self.train_transform, mode='train')\n",
    "        valid_ds = PatchCamelyonDataset(self.root, transform=self.valid_transform, mode='valid')\n",
    "        test_ds  = PatchCamelyonDataset(self.root, transform=self.valid_transform, mode='test')\n",
    "        \n",
    "        return train_ds, valid_ds, test_ds\n",
    "    \n",
    "    def get_dataloaders(self, batch_size, shuffle=True, pin_memory=True, num_workers=0):\n",
    "        \n",
    "        train_dl = DataLoader(\n",
    "            self.train_ds, batch_size=batch_size, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "        valid_dl = DataLoader(\n",
    "            self.valid_ds, batch_size=batch_size,\n",
    "            num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "        test_dl = DataLoader(\n",
    "            self.test_ds, batch_size=batch_size,\n",
    "            num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "        return train_dl, valid_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e271e71-81c0-4690-a3c0-3c5882ce770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfm = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0a4c5f58-8f69-45fa-9af0-4da357276193",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/niklas/Internal_HDD/project_data/histopathology/pcam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0413f57-e952-49c9-9d71-edda786aff99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcam = PatchCamelyon(root, train_transform=tsfm, valid_transform=tsfm, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "41148901-dfc8-4763-a1a5-8b843cc27f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, test_dl = pcam.get_dataloaders(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "97f735b6-0ba4-4287-aef5-1e0b0f6a4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c57d369-c06e-4892-89b9-b31ae6c7ceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 96, 96])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0010932c-b90c-475d-a1ce-10544f3d5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7008, 0.5384, 0.6916])\n",
      "tensor([0.2350, 0.2774, 0.2129])\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_mean_std(train_dl)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990ebfb-9cea-4090-a349-e1475cba977b",
   "metadata": {},
   "source": [
    "### NCT-CRC-HE-100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "285b1645-a0c9-4380-b1e5-a5c9854bb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/niklas/Internal_HDD/project_data/histopathology/NCT-CRC-HE-100K/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4af3713e-aac8-4d84-a41b-5deff1dd44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NctCrcHe100K:\n",
    "    \n",
    "    def __init__(self, root, train_transform, valid_transform, download=False, color_norm=True):\n",
    "        \n",
    "        self.root = root\n",
    "        self.train_transform = train_transform\n",
    "        self.valid_transform = valid_transform\n",
    "        self.color_norm = color_norm\n",
    "        \n",
    "        if download:\n",
    "            self.download_data()\n",
    "            \n",
    "        self.train_ds, self.valid_ds = self.prepare_datasets()\n",
    "        \n",
    "    \n",
    "    def download_data(self):\n",
    "        base_url = 'https://zenodo.org/record/1214456/files/'\n",
    "        download_and_extract_archive(base_url + 'NCT-CRC-HE-100K.zip', self.root)\n",
    "        download_and_extract_archive(base_url + 'NCT-CRC-HE-100K-NONORM.zip', self.root)\n",
    "        download_and_extract_archive(base_url + 'CRC-VAL-HE-7K.zip', self.root)\n",
    "    \n",
    "    \n",
    "    def prepare_datasets(self):\n",
    "        train_dir = 'NCT-CRC-HE-100K' if self.color_norm else 'NCT-CRC-HE-100K-NONORM'\n",
    "        \n",
    "        train_ds = ImageFolder(self.root/train_dir, self.train_transform)\n",
    "        valid_ds = ImageFolder(self.root/'CRC-VAL-HE-7K', self.valid_transform)\n",
    "        \n",
    "        return train_ds, valid_ds\n",
    "    \n",
    "    \n",
    "    def get_dataloaders(self, batch_size, shuffle=True, pin_memory=True, num_workers=0):\n",
    "        train_dl = DataLoader(\n",
    "            self.train_ds, batch_size=batch_size, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory\n",
    "        )\n",
    "        \n",
    "        valid_dl = DataLoader(\n",
    "            self.valid_ds, batch_size=batch_size,\n",
    "            num_workers=num_workers, pin_memory=pin_memory\n",
    "        )\n",
    "        \n",
    "        return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "98a38a78-4e25-4cc7-a12c-7301fa4cf0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nct = NctCrcHe100K(root, tsfm, tsfm, download=False, color_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e1abad58-88ef-4837-a360-9b0f8ed15b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = nct.get_dataloaders(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ea2f1fc4-f59f-4d9d-9fa9-85bcd8be4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bf11f3eb-8c93-4abf-96ae-b9598252768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d46efd62-2086-4f85-af46-0b7feb5c3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4fbc93fa-398d-44ff-9fc7-495961037fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7358, 0.5804, 0.7012])                                                                            \n",
      "tensor([0.2262, 0.2860, 0.2300])\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_mean_std(train_dl)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405824-f5c7-49af-b4e1-4fc90279d814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
